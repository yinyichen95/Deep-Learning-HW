from __future__ import division
from nltk.util import ngrams
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import tqdm
import sys
import math
import nltk
from collections import *
import os
from nltk.translate.bleu_score import sentence_bleu
import nltk

# English source data
with open("data/train_1.en", "r", encoding="utf-8") as f:
    source_text = f.read()

# Vietnamese target data
with open("data/train_1.vi", "r", encoding="utf-8") as f:
    target_text = f.read()

# English Dictionary
source_vocab = list(set(source_text.lower().split()))

# Vietnamese Dictionary
target_vocab = list(set(target_text.lower().split()))

#
SOURCE_CODES = ['<PAD>', '<UNK>']
TARGET_CODES = ['<PAD>', '<EOS>', '<UNK>', '<GO>']

# English mapping dictionary
source_vocab_to_int = {word: idx for idx, word in enumerate(SOURCE_CODES + source_vocab)}
source_int_to_vocab = {idx: word for idx, word in enumerate(SOURCE_CODES + source_vocab)}

# Vietnamese mapping dictionary
target_vocab_to_int = {word: idx for idx, word in enumerate(TARGET_CODES + target_vocab)}
target_int_to_vocab = {idx: word for idx, word in enumerate(TARGET_CODES + target_vocab)}


# Number of Epochs
epochs = 100
# Batch Size
batch_size = 256
# RNN Size
rnn_size = 512
# Number of Layers
rnn_num_layers = 3
# Embedding Size
encoder_embedding_size = 256
decoder_embedding_size = 256
# Learning Rate
lr = 0.0005
# print result
display_step = 100


def text_to_int(sentence, map_dict, max_length, is_target=False):

    # Pad sentences with <PAD> so that each sentence of a batch has the same length
    text_to_idx = []
    # unk index
    unk_idx = map_dict.get("<UNK>")
    pad_idx = map_dict.get("<PAD>")
    eos_idx = map_dict.get("<EOS>")

    if not is_target:
        for word in sentence.lower().split():
            text_to_idx.append(map_dict.get(word, unk_idx))

    else:
        for word in sentence.lower().split():
            text_to_idx.append(map_dict.get(word, unk_idx))
        text_to_idx.append(eos_idx)

    if len(text_to_idx) > max_length:
        return text_to_idx[:max_length]

    else:
        text_to_idx = text_to_idx + [pad_idx] * (max_length - len(text_to_idx))
        return text_to_idx


# transfer the source Tx = 50
source_text_to_int = []

for sentence in tqdm.tqdm(source_text.split('\n')):
    source_text_to_int.append(text_to_int(sentence, source_vocab_to_int, 50, is_target=False))

# transfer the target  Ty = 60
target_text_to_int = []

for sentence in tqdm.tqdm(target_text.split('\n')):
    target_text_to_int.append(text_to_int(sentence, target_vocab_to_int, 60, is_target=True))


X = np.array(source_text_to_int)
Y = np.array(target_text_to_int)


def model_inputs():

    # Implement Function
    inputs = tf.placeholder(tf.int32, [None, None], name="inputs")
    targets = tf.placeholder(tf.int32, [None, None], name="targets")
    learning_rate = tf.placeholder(tf.float32, name="learning_rate")
    source_sequence_len = tf.placeholder(tf.int32, (None,), name="source_sequence_len")
    target_sequence_len = tf.placeholder(tf.int32, (None,), name="target_sequence_len")
    max_target_sequence_len = tf.placeholder(tf.int32, (None,), name="max_target_sequence_len")

    return inputs, targets, learning_rate, source_sequence_len, target_sequence_len, max_target_sequence_len


def encoder_layer(rnn_inputs, rnn_size, rnn_num_layers, source_sequence_len, source_vocab_size, encoder_embedding_size):

    # Create encoding layer
    encoder_embed = tf.contrib.layers.embed_sequence(rnn_inputs, source_vocab_size, encoder_embedding_size)

    # LSTM
    def get_lstm(rnn_size):
        lstm = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123))
        return lstm

    # stack rnn_num_layers' LSTM
    lstms = tf.contrib.rnn.MultiRNNCell([get_lstm(rnn_size) for _ in range(rnn_num_layers)])
    encoder_outputs, encoder_states = tf.nn.dynamic_rnn(lstms, encoder_embed, source_sequence_len, dtype=tf.float32)

    return encoder_outputs, encoder_states


def decoder_layer_inputs(target_data, target_vocab_to_int, batch_size):

    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])
    decoder_inputs = tf.concat([tf.fill([batch_size, 1], target_vocab_to_int["<GO>"]), ending], 1)

    return decoder_inputs


def decoder_layer_train(encoder_states, decoder_cell, decoder_embed,
                        target_sequence_len, max_target_sequence_len, output_layer):

    # Create a decoding layer for training
    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_embed, sequence_length=target_sequence_len,
                                                       time_major=False)

    training_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, training_helper, encoder_states, output_layer)

    training_decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder, impute_finished=True,
                                                                  maximum_iterations=max_target_sequence_len)

    return training_decoder_outputs


def decoder_layer_infer(encoder_states, decoder_cell, decoder_embed, start_id, end_id,
                        max_target_sequence_len, output_layer, batch_size):

    # Create a decoding layer for inference
    start_tokens = tf.tile(tf.constant([start_id], dtype=tf.int32), [batch_size], name="start_tokens")

    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embed, start_tokens, end_id)

    inference_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, inference_helper, encoder_states, output_layer)

    inference_decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder, impute_finished=True,
                                                                      maximum_iterations=max_target_sequence_len)

    return inference_decoder_outputs


def decoder_layer(encoder_states, decoder_inputs, target_sequence_len, max_target_sequence_len, rnn_size, rnn_num_layers,
                   target_vocab_to_int, target_vocab_size, decoder_embedding_size, batch_size):

    # Create decoding layer
    decoder_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoder_embedding_size]))
    decoder_embed = tf.nn.embedding_lookup(decoder_embeddings, decoder_inputs)

    def get_lstm(rnn_size):
        lstm = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=456))
        return lstm

    decoder_cell = tf.contrib.rnn.MultiRNNCell([get_lstm(rnn_size) for _ in range(rnn_num_layers)])

    # output_layer logits
    output_layer = tf.layers.Dense(target_vocab_size)

    with tf.variable_scope("decoder"):
        training_logits = decoder_layer_train(encoder_states, decoder_cell, decoder_embed,
                                               target_sequence_len, max_target_sequence_len, output_layer)

    with tf.variable_scope("decoder", reuse=True):
        inference_logits = decoder_layer_infer(encoder_states, decoder_cell, decoder_embeddings,
                                               target_vocab_to_int["<GO>"], target_vocab_to_int["<EOS>"],
                                                max_target_sequence_len, output_layer, batch_size)

    return training_logits, inference_logits


def seq2seq_model(input_data, target_data, batch_size, source_sequence_len, target_sequence_len, max_target_sentence_len,
                 source_vocab_size, target_vocab_size, encoder_embedding_size, decoder_embeding_size,
                 rnn_size, rnn_num_layers, target_vocab_to_int):

    # Build the Sequence-to-Sequence part of the neural network
    _, encoder_states = encoder_layer(input_data, rnn_size, rnn_num_layers, source_sequence_len,
                                      source_vocab_size, encoder_embedding_size)

    decoder_inputs = decoder_layer_inputs(target_data, target_vocab_to_int, batch_size)

    training_decoder_outputs, inference_decoder_outputs = decoder_layer(encoder_states, decoder_inputs,
                                                                      target_sequence_len, max_target_sentence_len,
                                                                      rnn_size, rnn_num_layers,
                                                                      target_vocab_to_int, target_vocab_size,
                                                                      decoder_embeding_size, batch_size)
    return training_decoder_outputs, inference_decoder_outputs


def get_batches(sources, targets, batch_size):
    """
    Batch targets, sources, and the lengths of their sentences together
    """
    for batch_i in range(0, len(sources)//batch_size):
        start_i = batch_i * batch_size

        # Slice the right amount for the batch
        sources_batch = sources[start_i:start_i + batch_size]
        targets_batch = targets[start_i:start_i + batch_size]

        # Need the lengths for the _lengths parameters
        targets_lengths = []
        for target in targets_batch:
            targets_lengths.append(len(target))

        source_lengths = []
        for source in sources_batch:
            source_lengths.append(len(source))

        yield sources_batch, targets_batch, source_lengths, targets_lengths


def sentence_to_seq(sentence, source_vocab_to_int):

    # Convert a sentence to a sequence of ids
    unk_idx = source_vocab_to_int["<UNK>"]
    word_idx = [source_vocab_to_int.get(word, unk_idx) for word in sentence.lower().split()]

    return word_idx


# Check command
if len(sys.argv) < 2:
    print('No action excuted')
    sys.exit()


# Train
elif sys.argv[1] == 'train':

    print('Processing Data')
    print("ENG_VOCAB: {}".format(len(source_vocab)))
    print("VIE_VOCAB: {}".format(len(target_vocab)))
    print("Size of English Map: {}".format(len(source_vocab_to_int)))
    print("Size of Vietnamese Map: {}".format(len(target_vocab_to_int)))

    train_graph = tf.Graph()

    with train_graph.as_default():
        inputs, targets, learning_rate, source_sequence_len, target_sequence_len, _ = model_inputs()

        max_target_sequence_len = 60
        train_logits, inference_logits = seq2seq_model(tf.reverse(inputs, [-1]), targets, batch_size, source_sequence_len,
                                                      target_sequence_len, max_target_sequence_len,
                                                      len(source_vocab_to_int), len(target_vocab_to_int),
                                                      encoder_embedding_size, decoder_embedding_size,
                                                      rnn_size, rnn_num_layers, target_vocab_to_int)

        training_logits = tf.identity(train_logits.rnn_output, name="logits")
        inference_logits = tf.identity(inference_logits.sample_id, name="predictions")

        masks = tf.sequence_mask(target_sequence_len, max_target_sequence_len, dtype=tf.float32, name="masks")

        with tf.name_scope("optimization"):
            # Loss function
            cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks)

            # Optimizer
            optimizer = tf.train.AdamOptimizer(learning_rate)

            # Gradient Clipping
            gradients = optimizer.compute_gradients(cost)
            clipped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]
            train_op = optimizer.apply_gradients(clipped_gradients)

    with tf.Session(graph=train_graph) as sess:
        sess.run(tf.global_variables_initializer())

        for epoch_i in range(epochs):
            for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(
                    get_batches(source_text_to_int, target_text_to_int, batch_size)):

                _, loss = sess.run([train_op, cost], {inputs: source_batch, targets: target_batch,
                     learning_rate: lr, source_sequence_len: sources_lengths, target_sequence_len: targets_lengths})

                if batch_i % display_step == 0 and batch_i > 0:

                    batch_train_logits = sess.run(
                        inference_logits,
                        {inputs: source_batch, source_sequence_len: sources_lengths, target_sequence_len: targets_lengths})

                    print('Epoch {:>3} Batch {:>4}/{} - Loss: {:>6.4f}'
                          .format(epoch_i, batch_i, len(source_text_to_int) // batch_size, loss))

        # Save Model
        saver = tf.train.Saver()
        saver.save(sess, "checkpoints/dev")
        print('Model Trained and Saved')


# Test
elif sys.argv[1] == 'test':

    with open("data/tst2013.en", "r", encoding="utf-8") as ts:
        source_text_ts = ts.read()

    with open("data/tst2013.vi", "r", encoding="utf-8") as ts:
        target_text_ts = ts.read()

    loaded_graph = tf.Graph()

    score = []

    with tf.Session(graph=loaded_graph) as sess:
        # Load saved model
        loader = tf.train.import_meta_graph('checkpoints/dev.meta')
        loader.restore(sess, tf.train.latest_checkpoint('./checkpoints'))
        input_data = loaded_graph.get_tensor_by_name('inputs:0')
        logits = loaded_graph.get_tensor_by_name('predictions:0')
        target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_len:0')
        source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_len:0')

        for source_sentence_test, target_sentence_test in zip(source_text_ts.split("\n"), target_text_ts.split("\n")):
            test_sentence = sentence_to_seq(source_sentence_test, source_vocab_to_int)
            target_sentence = sentence_to_seq(target_sentence_test, target_vocab_to_int)

            test_logits = sess.run(logits, {input_data: [test_sentence]*batch_size,
                                                 target_sequence_length: [len(test_sentence)*2]*batch_size,
                                                 source_sequence_length: [len(test_sentence)]*batch_size})[0]

            reference = [[target_int_to_vocab[i] for i in target_sentence]]
            candidate = [target_int_to_vocab[i] for i in test_logits]
            cc1 = nltk.translate.bleu_score.SmoothingFunction()
            score.append(sentence_bleu(reference, candidate, smoothing_function=cc1.method1))
            print(" ".join([target_int_to_vocab[i] for i in test_logits]))

        print('BLEU: {}'.format(np.sum(score, dtype=np.float32)))


# Translate
elif sys.argv[1] == 'translate':

    translate_sentence_text = input("Please input a sentence: ")

    translate_sentence = sentence_to_seq(translate_sentence_text, source_vocab_to_int)

    loaded_graph = tf.Graph()
    with tf.Session(graph=loaded_graph) as sess:
        # Load saved model
        loader = tf.train.import_meta_graph('checkpoints/dev.meta')
        loader.restore(sess, tf.train.latest_checkpoint('./checkpoints'))
        input_data = loaded_graph.get_tensor_by_name('inputs:0')
        logits = loaded_graph.get_tensor_by_name('predictions:0')
        target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_len:0')
        source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_len:0')

        translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,
                                             target_sequence_length: [len(translate_sentence)*2]*batch_size,
                                             source_sequence_length: [len(translate_sentence)]*batch_size})[0]

    print(" ".join([target_int_to_vocab[i] for i in translate_logits]))


else:
    print('No action excuted')
